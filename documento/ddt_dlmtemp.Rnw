\documentclass[12pt]{article}
\usepackage[utf8]{inputenc} 
\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage[spanish, es-tabla]{babel}
\usepackage[auth-sc,affil-sl]{authblk}
%\usepackage[latin1]{inputenc}
\usepackage[spanish]{babel}
\decimalpoint
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{subfig}

%\usepackage[style=authoryear]{biblatex}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{setspace}
\usepackage[all]{xy}
%\usepackage{fullpage}
\usepackage{longtable}
%\usepackage {fancyvrb}
\usepackage{fancyhdr}
%\usepackage{color}
\usepackage{pstricks}
\usepackage{amsthm}
%\usepackage{harvard}
\usepackage{float}
\usepackage{footmisc}
%\usepackage[]{draftwatermark}
%\SetWatermarkText{18 de Diciembre-Versi\'on global}
%\SetWatermarkLightness{0.8}
%\SetWatermarkScale{2}

% 
\setlength{\parindent}{0pt}
\setlength{\textwidth}{6.3in}
\setlength{\topmargin}{-33pt}
\setlength{\oddsidemargin}{0pt}
\setlength{\evensidemargin}{0pt}
\setlength{\textheight}{8in}


% cosas del authblk
\setlength{\parskip}{20pt}
\setlength{\affilsep}{1mm}
\renewcommand\Authfont{\small} %\scshape\normalsize
\renewcommand\Affilfont{\itshape\small}

\renewcommand\Authsep{  }
\renewcommand\Authand{ }
\renewcommand\Authands{ }

\newcommand{\abs}[1]{ \lvert #1 \rvert }
\newcommand{\sii}{\Leftrightarrow}
\newcommand{\limi}{\liminf_n A_n}
\newcommand{\lims}{\limsup_n A_n}
\newcommand{\then}{\Rightarrow}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\norm}[1]{\lvert \lvert #1 \rvert \rvert}
\newcommand{\prob}{\stackrel{p}{\to}}
\newcommand{\ton}{\stackrel{n}{\to}\,}
\newcommand{\E}{\mathbb{E} \,}
\newcommand{\limn}{\lim_{n\to +\infty}}
\newcommand{\cuadro}[3]{\setbox0\hbox{#1 \hspace{-1em}\raisebox{1em}{$\downarrow$}} \clap{\hbox to \wd0{\raisebox{#2\height}{#3}}}\box0 \;}
\newcommand{\cuadrodos}[3]{\setbox0\hbox{#1}  \llap{\hbox to \wd0{\raisebox{#2\height}{#3}}}\box0 \;}
\newcommand{\cs}{\stackrel{c.s.}{\to}}
\newcommand{\ind}[1]{1\hspace{-0.35em}1_{ \{ #1 \} } }
\newcommand{\mean}[1]{\bar{#1}_n}
\newcommand{\MAS}{$X_1, \dots, X_n$ MAS de $X$ }
\newcommand{\minim}{X_{(1:n)}}
\newcommand{\p}{\mathbb{P}}
\newcommand{\up}[1]{\stackrel{\text{#1}}{=}}
\newcommand{\f}{\mathcal{F}}
\newcommand{\bb}[1]{\bold{#1}}
\newcommand{\prodi}[1]{\left\langle #1 \right\rangle}
%\newcommand{\norm}[1]{\left\langle #1 \right\rangle}

\usepackage{tikz}
\usetikzlibrary{automata,arrows,positioning,calc}
\graphicspath{{../graf/}}


% definiciones
\newcommand{\keywordname}{Palabras clave}
\newenvironment{keywords}{%
	\paragraph*{\keywordname: }}%
{}{}
\newcommand{\area}{{\bf Área:} {\sc Métodos Matemático-Cuantitativos.}}%{\small}

%********************************************%********************************************%********************************************

<<setup,echo=F>>=
opts_chunk$set(echo=FALSE,message=F,warning = F,fig.align = "center",fig.height=3,highlight = T,echo=F)
# ... me ha pasado que no es lo mas adecuado meter cache para todo indiscriminadamente, 
# despues haces un cambio y no pasa nada y te rompes la cabeza de porque el codigo no esta funcionando ... es por el cache
# nada, creo que es mejor incluir la opcion cache en los chunk individuales donde se precisa
@


<<paquetes,include=F>>=
paquetes <- c("knitr","xtable","ggplot2","tidyverse","dlm", "lubridate")
sapply(paquetes,require,character.only=T)
load(file = "d1")
load(file = "d2")
@


\begin{document}
	
	\thispagestyle{empty} 
	\begin {center}
	\includegraphics[width=0.40\textwidth]{logo_iesta.png}
		
	UNIVERSIDAD DE LA REPÚBLICA
	
	Facultad de Ciencias Económicas y Administración

	Instituto de Estadística\\
	\vspace{4.5 cm}
\textbf{\Large Titulo}	
\vspace{1.5 cm}
	
\textbf{Manuel Hernández Banadik};
\textbf{Ignacio Álvarez-Castro}\\
\vspace{0.5 cm}
	
\textbf{Abril, 2019}
\end{center}
\vspace{1.5cm}

\begin{center}
{\Huge \textbf{Serie Documentos de Trabajo}}\\
\vspace{1.0 cm}
\noindent  DT (numero) - ISSN : 1688-6453 
\end{center}
\pagebreak
\thispagestyle{empty} 
\vspace{15.5cm}

Forma de citación sugerida para este documento: 
\begin{flushleft}
\textbf{queda de postre ... }
\end{flushleft}

\newpage

\setcounter{page}{1} 
\thispagestyle{empty} 

\begin{center}
	\textbf{Titulo ... }
\end{center}

\begin{center}
  Manuel Hernández Banadik \footnote{\emph{email: }\texttt{mhernandez@iesta.edu.uy}, ORCID: 0000-0002-2505-4238\label{fn:foot_Manuel}};	Ignacio Álvarez-Castro \footnote{\emph{email: }\texttt{nachalca@iesta.edu.uy}, ORCID: 0000-0003-3123-2165\label{fn:foot_Nacho}}\\
		{\small \emph{Instituto de Estadística, Facultad de Ciencias Económicas y de Administración, Universidad de la República}}
\end{center}

\begin{center}
\textbf{RESUMEN}
\end{center}

Contamos con datos de mediciones diarias de temperaturas mínimas y máximas, de una estación meteorológica de Uruguay, desde Enero-1950 a Octubre-2014.

Se define una ola de frío, como un período de tiempo en el cual, la temperatura observada es inferior a un umbral. El objetivo es determinar dicho umbral a través de la estimación del percentil 10 de las temperaturas. Utilizaremos los modelos lineales dinámicos para modelar la serie, y para la estimación de los percentiles.

\section{Introducción}
El estudio de eventos extremos ha tomado una gran relevancia en los últimos años debido principalmente al gran impacto que presentan en la sociedad y la economía de los países, así como en los ecosistemas. Dentro de la región del Sudeste de Sudamérica los principales eventos climáticos extremos que han sido analizados son los relacionados con la temperatura (olas de calor y de frío, heladas, días cálidos, etc) y a la precipitación (sequías, precipitaciones intensas, etc). Muchos de estos estudios son relativamente actuales, debido principalmente a que es necesario contar con series temporales lo suficientemente largas y fundamentalmente completas, a un paso temporal de por lo menos un día y de alta calidad. 

Bajo el escenario de cambio climático, es necesario comprender cómo los eventos extremos cambian en frecuencia y/o intensidad, identificando cómo se han comportado en las últimas 3 o 4 décadas. Identificar este tipo de eventos ayudará a comprender su dinámica para luego realizar previsiones a un plazo menor asociado a la variabilidad climática y hasta incluso estudiar el comportamiento a escala sinóptica o de días. Uruguay cuenta con registros suficientemente largos en ciertos puntos del país, pero se han detectado muchos períodos sin información, tanto para temperaturas extremas diarias como para la variable precipitación (Renom, 2009; Amiel, 2012)

En este trabajo se presenta la estimación y caracterización de olas de frio en una estación meteorológica basadas en modelos dinámicos de la serie de temperaturas diarias máximas y mínimas en dicha estación. 

La siguiente sección presenta los datos utilizados y una definición de ola de frío. Luego, en la sección \ref{DLM} introducimos la familia de Modelos Lineales Dinámicos, que fueron usados para modelar los datos, así como la estimación de los percentiles. En la sección \ref{implementacionR} mostramos la implementación en \textbf{R} de la estimación de un modelo simulado. En la sección \ref{DLMtemp} aplicamos la metodología descripta a los datos de temperaturas de Uruguay y presentamos los resultados.

\section{Los datos}

Contamos con información de la temperatura máxima y mínima diaria en la estación meteorológica Estanzuela para el período XXX a ZZZ. Definimos $\{Y^n_{at}\}$ y $\{Y^x_{at}\}$ la serie diaria de temperaturas mínima y máxima respectivamente, para $t \in \{1,\dots, 365\}$ y $a \in \{1950,\dots, 2014\}$ (\textcolor{blue}{te parece bien esta notación?? si es asi hay que adaptar todo lo demás a esto})

Existen diversas formas de caracterizar una racha de frío, que responden a distintas aplicaciones de su estudio. Las diversas definiciones acuerdan en la necesidad de establecer un umbral de bajas temperaturas (puede ser absoluto o relativo) y en delimitar una ventana de tiempo durante la cual, la temperatura observada debe mantenerse por debajo del umbral definido. 

En el presente trabajo, hemos definido una ola de frío como un período de tiempo mayor o igual a 3 días, en los cuales las temperaturas mínimas y máximas son inferiores a los respectivos percentiles 10 esperados para tales días. Definimos el percentil 10 de mínima como $p^n_{10_t}:= \inf\{y: \p(Y^n_t \leq y)\geq 0.1\}$. Análogamente definimos el percentil 10 de máxima para el día $t$ como $p^x_{10_t}:= \inf\{y: \p(Y^x_t \leq y)\geq 0.1\}$. Podemos decir entonces que una sucesión de días $t_1, \dots, t_k$ constituyen una ola de frío de largo $k$ si, siendo $k\geq 3$, se cumple simultáneamente que:

$\begin{cases} y^n_{t_i} < p^n_{10_i}  \\ y^x_{t_i} < p^x_{10_i} \end{cases}$ para $i=1,\dots,k$

Vizualizar fenómenos de olas de extremos no es trivial, aplicando la definición anterior, debemos tenr en cuenta varios factores. En primer lugar la condición recae simultaneamente sobre la temperatura mínima y máxima por lo que debemos prestar atención a ambas series. Al mismo tiempo debemos comparar la temperatura de cada día en particular con los percentiles para ese día, o más en general, con las temperaturas esperables. Finalmente, los días deben ser consecutivos para formar una ola de extremos. 

La figura \ref{fig:graf1} muestra las series de temperaturas para el año 2012 (\textcolor{blue}{la serie es del 2012 o 2011 ???}) su la distribución de frecuencias. El gráfico tiene 3 capaz básicas, en primer lugar calculamos un histograma bidimensional en que los bins son hexágonos en el plano de $\{ y^n_{ta}, t$ (panel superior), la intensidad del color representa la frecuencia. Sobre el histograma se dibuja las series de temperatura observada para cada día en 2012 y finalmente se divide en dos paneles con la serie de mínima (superior) y máxima (inferior) por separado. 

<<graf1,fig.height=4,fig.cap="Gráfico">>=
#d1 <- serie[(365*62):(365*63),] %>% select(-(Tn.pred:ola)) %>% gather(serie,temp,-dia,-year,-fecha)

#d2 <- serie %>% select(dia:Tx) %>% gather(serie,temp,-dia,-fecha,-year)

#save(file="d1",d1)
#save(file="d2",d2)

#ggplot(d1,aes(x=dia,y=temp,group=serie))+geom_line()+facet_grid(serie~.)+geom_boxplot(data = d2,aes(x=dia,y=temp,col=serie,group=dia),size=.5,alpha=0.1)

# -------------------
# plot1 <- ggplot()+geom_boxplot(data = d2,aes(x=dia,y=temp,col=serie),size=0.5,alpha=0.1)+facet_grid(serie~.,scales="free_y")+geom_line(data=d1,aes(x=dia,y=temp,group=serie))+annotate("rect", xmin="06-05", xmax="06-09", ymin=-4 , ymax=30, alpha=0.2, color=NA, fill="blue")
# 
# d3 <- plot1$layers[[3]]$data
# d3 <- rbind(d3,d3)
# d3 <- cbind(d3,serie=c("Tn","Tx"))
# d3[1,3:4] <- c(-2,20)
# d3[2,3:4] <- c(5,28)
# 
# plot1$layers[[3]]$data <- d3
# plot1

# ------------------------
# Buen dibujo !!! 
# la misma idea trate de mejorarlo ... a ver si te gusta
una.ola <- data.frame( serie = 'Tn', xn=156, xx=160, yn=-2, yx=20 ) %>% 
  bind_rows( data.frame( serie = 'Tx', xn=156, xx=160, yn=5, yx=28 ) )

d2 %>% mutate(dia2 = yday(fecha)) %>% 
  ggplot() + 
  geom_hex(aes(x=dia2, y=temp) ) +  
  geom_line(data = mutate(d1, dia2 = yday(fecha)),  aes(x=dia2,y=temp,group=serie)) +
  geom_rect( data = una.ola, 
             aes(xmin=xn, xmax=xx, ymin=yn , ymax=yx), 
             alpha=0.2, color=NA, fill="red") + 
  facet_grid(serie~., scales = 'free_y') +
  scale_fill_gradient(name='Frequence', high = '#034e7b', low = '#f1eef6') +
  theme_bw()
@
\textcolor{blue}{en la figura: caption con descripcion, nombres de los ejes y la etiqueta de color, nombres de los paneles}

El período de días del 5 al 9 de junio de 2012 (señalado en rojo en la Figura \ref{fig:graf1}) la temperatura observada se acerca a la cola inferior de la distribución para ese día. Eso indica que ese período fue bastante más frio de lo esperado, podemos considerar que durante esos días estuvimos ante la presencia de una \textit{ola de frío}. 

\textcolor{blue}{comentario de cierre??}

\section{Modelos lineales dinámicos}\label{DLM}

%Los modelos lineales dinámicos (DLM) son una familia de modelos de espacio de estado. Procesos muy conocidos pueden ser vistos como modelos DLM: el paseo al azar, el modelo de regresión normal, los modelos ARIMA, entre otros.
%
%Un modelo estadístico de posición, establece que hay un parámetro del cual tenemos observaciones ruidosas. %Podemos extender esa idea, y considerar que tenemos obervaciones ruidosas de un
%Podemos extender la idea de parámetro 

Los modelos lineales dinámicos (DLM) son una familia de modelos que constituye una subclase de los llamados modelos de espacio de estado. En DLM se considera una serie de tiempo, $Y_t$, como una observación ruidosa de un proceso dinámico no observable $\theta_t$. Estos modelos se definen a través de dos ecuaciones básicas: una \textit{ecuación de evolución} y una \textit{ecuación de observación}. La estructura general de un DLM se muestra en \eqref{ecu.obs} y \eqref{ecu.evo} donde $F_t$ $G_t$ son dos matrices conocidas de orden $p\times p$ y $m\times p$ respectivamente que caracterizan al modelo, las perturbaciones $v_t$ y $w_t$ son son secuencias de vectores gausianos independientes, mientras que $V_t,W_t$ serán los parámetros que caractericen el modelo. Adicionalmete, se agrega una previa Normal para el momento inicial, es decir $\theta_0 \sim N(m_0, C_0)$. 

\begin{eqnarray}
\label{ecu.obs} Y_t&= F_t\theta_t + v_t  \;&\;  v_t \sim \mathcal{N}(0,V_t) \\
\label{ecu.evo} \theta_t &= G_t \theta_{t-1} + w_t \;&\; w_t \sim \mathcal{N}(0,W_t)
%\label{eq:modelo}
\end{eqnarray} 

La ecuación de evolución responde a la dinámica del proceso estocástico: define cómo se vincula el estado del proceso en tiempo $t$ con su estado en tiempo $t+1$. Por otro lado, la ecuación de observación, explicita cómo es observado el proceso en tiempo $t$ dado el estado en el que se encuentra a tiempo $t$. En ambas ecuaciones, se puede introducir una componente aleatorio. 

\subsection{Estructura de un DLM}

La estructura de depencia entre las observaciones es un aspecto clave para entender como funcionan los DLM. Al igual que la clase maás general de modelos espacio-estado en los DLM se basa en dos supuestos fundamentales. En primer lugar se asume  que el proceso inobservable o proceso de estado $\theta_t$ consituye una cadena de Markov.  En tanto, las observaciones $Y_t$ son condicionalmente independientes dado $\theta_t$ y se asume que $Y_t$ depende únicamente de $\theta_t$. 

\begin{center}
\begin{tikzpicture}[->, >=stealth', auto, semithick, node distance=3cm]
\tikzstyle{every state}=[fill=white,draw=black,thick,text=black,scale=1]
\node[state]    (A)                     {$\theta_t$};
\node[state]    (B)[above of=A]   {$Y_t$};
\node[state]    (D)[right of=A]   {$\theta_{t+1}$};
\node[state]    (C)[above of=D]   {$Y_{t+1}$};
\node[state]    (E)[left of=A]   {$\theta_{t-1}$};
\node[state]    (F)[left of=B]   {$Y_{t-1}$};
\path
(E) edge[right]     node{}         (A)
(A) edge[left]     node[label={[shift={(0.15,-.6)}] \scriptsize{evolución}}] {}         (D)
%     edge[bend left]     node{$(1-p)^2$}     (B)
%     edge[bend left,below]      node{$p(1-p)$}      (D)
%     edge[bend right]    node{$p(1-p)$}      (C)
% (B) edge                node{$1$}           (D)
% (C) edge                node{$1$}           (D)
% (D) edge[loop right]    node{$(1-q)^2$}     (D)
%     edge[bend right,right]    node{$q(1-q)$}      (B)
%     edge[bend left]     node{$q(1-q)$}      (C)
(E)    edge (F)
(D) edge (C)
(A)    edge[above]     node[label={[shift={(0.85,-0.5)}] \scriptsize{observación}}] {}         (B);

%\node[above=0.5cm] (A){Patch G};
%\draw[red] ($(D)+(-1.5,0)$) ellipse (2cm and 3.5cm)node[yshift=3cm]{Patch H};
\end{tikzpicture}
\captionof{figure}{Diagrama de evolución y observación del proceso}\label{diagrama}
\end{center}

La figura \ref{diagrama} representa un diagrama de la estructura de depndencia en DLM, donde los arcos indican dependencia estadistica. Se puede ver como  $\theta_t$, toda la dependencia entre observaciones pasa a través del proceso latente. A partir de esta estructura, se puede considerar que las observaciones representan una medida ruidosa el proceso de estado.

La principal consecuencia de la estructura de dependencia es que la distribucion conjunta de todas las variables de interes queda determinada por la distribucion previa del estado inicial y las densidades condicionales $p(\theta_t | \theta_{t-1})$, $p(y_t|\theta_t)$, de forma: 
\[
p(\theta_{0:t}, y_{1:t}) =  p(\theta_0) \prod_{j=1}^t  p(\theta_j | \theta_{j-1})  p(y_j|\theta_j)
\]

La famillia de DLM es amplia y flexible, muchos modelos estadisticos para datos temporales pueden verse como casos partiulares de esta familia o de la clase mas general de modelos espacio-estados. En particular los modelos ARMA con ruido gaussiano son equivalentes a DLM cuando los parametros $F_t, G_t, V_t, W_t$ son constantes en el tiempo. Por ejemplo, el proceso  AR(2) $y_t = \phi_1 y_{t-1} + \phi_2 y_{t-2} + e_t$, puede ser visto como un DLM si definimos $\theta_t = 
\begin{pmatrix}
y_t \\
y_{t-1}
\end{pmatrix}
$
entonces, tenemos que:  

\[ \begin{array}{ll}
y_t = & \begin{bmatrix}
1 \\
0
\end{bmatrix}
\theta_t \\
\theta_t = &
\begin{bmatrix}
\phi_1 & \phi_2 \\
1 & 0
\end{bmatrix}
\theta_{t-1}
+
\begin{bmatrix}
e_t \\
0
\end{bmatrix}
\end{array}
\]

Aparte de DLM, la familia de modelos espacio-estados admite modelos no lineales y el uso de otras distribuciones no Gausianas. Por ejemplo, modelos para las distribuciones de la familia exponencial pueden ser especificados para tener DLMG \textit{generalizados}, por otro lado en casos uqe el proceso de estados tenga una distribucion discreta el modelo es referido como modelos ocultos de MArkov, tambien modelos de volatilidad estocastica pueden ser vistos como espacio-estados. El estudio de DLM entonces, es relevante pues permite introucirnos al trabajo con una familia de modelos que es muy amplica y puede aplicarse en una gran variedad de problemas concretos. 


%\begin{center}
%$\begin{array}{lc}
%Y_t=F_t\theta_t + v_t  &  v_t \sim \mathcal{N}(0,V_t) \\
%\theta_t = G_t \theta_{t-1} + w_t \;\; & w_t \sim \mathcal{N}(0,W_t)
%\end{array}$
%\end{center}

\subsection{Estimacion del proceso de estados}

Si se tienen las observaciones $y_1,\dots,y_T$, y se asume un modelo como el descripto por las ecuaciones \eqref{ecu.obs} y \eqref{ecu.evo}, hay varias distribuciones posteriores que puede ser de interes. En relacion al proceso no observable se distinguen tres distribuciones relevantes condicional en los datos observados: filtrada, suavisada y de prediccion. 

La \textbf{distribucion filtrada} (filtering distribution en ingles) consiste en la distribucion posteiror del estado no observable $\theta_t$ dada la informacion observada hasta ese mismo momento, es decir $p(\theta_t | y_1, \ldots, y_t)$, se tiene una distribucion para cada momento $t$. La posterior filtrada es de principal interes en aplicaciones secuenciales donde es necesario realizar una nueva estimacion para cada observacion nueva. En el caso de modelos DLM, donde operan las restricciones de normalidad y linealidad, es posible tener soluciones cerradas para $p(\theta_t | y_1, \ldots, y_t)$ mediante el Filtro de Kalman (REF??) \textcolor{blue}{es necesario incluir las formulas de recursion para estimar esto??}

Una segunda distribucion posterior que puede tener relevancia en aplicaciones es la \textbf{distribucion suavizada} (smoothing distribution en ingles) del proceso de estados. La distribucion suavizada consiste en $p(\theta_t | y_1, \ldots, y_T)$, es similar a la posterior filtrada con la diferencia que el condicional se realiza sobre todos los datos observados disponibles. La distribucion suavizada es relevante para aplicaciones donde estamos interesados en un estudio retrospectivo y se desea analizar todo el proceso de estados latente. \textcolor{blue}{a nosotros no deberia interesarnos mas smoothing que filtering ???}

\textcolor{blue}{estimacion de los parametros de varianza? MLE.. otra forma?}

En caso que estemos interesados en predecir un valor futuro del estado se utilizan distribuciones de prediccion $p(\theta_{t+k} | y_1, \ldots, y_t)$. \textcolor{blue}{expandir y comentar sobre predictiva de observaciones}

\textcolor{blue}{Incluir tratamiento de datos faltantes, caapz que para que se entienda son necesarias incluir formulas para calcular filtering y smoothing}


\subsection{Implementación computacional en \textbf{R}}\label{implementacionR}

La figura \ref{fig:graf7} muestra un ejemplo simulado de un proceso univariado concebido de esta forma, bajo el modelo descripto en \eqref{dlm_sim}. Así mismo, se muestra la estimación del proceso $\theta_t$ obtenida a través de la implementación del filtro de Kalman en \textbf{R}.

\begin{equation}
\begin{aligned}
Y_t&=\theta_t + v_t  \;&\;  v_t \sim \mathcal{N}(0,0.1^2) \\
\theta_t &= \theta_{t-1} + w_t \;&\; w_t \sim \mathcal{N}(0,0.3^2)
\end{aligned}
\label{dlm_sim}
\end{equation}

En este caso $G_t$ y $F_t$ se definieron constantes con valor 1. El proceso $\{\theta_t\}$ describe un paseo al azar, mientras que podemos considerar a $\{y_t\}$ como una observación ruidosa de $\{\theta_t\}$

\definecolor{theta}{HTML}{F8766F}
\definecolor{ye}{HTML}{7CAE00}
\newcommand{\thetaline}{\raisebox{2pt}{\tikz{\draw[-,theta,-,line width = 0.9pt](0,0) -- (5mm,0); }}\;}
\newcommand{\yeline}{\raisebox{2pt}{\tikz{\draw[-,ye,-,line width = 0.9pt](0,0) -- (5mm,0); }}\;}

<<>>=
set.seed(1237)
N <- 100
t <- seq(0,1,,N)
w <- rnorm(N,0,.1)
v <- rnorm(N,0,.3)
theta <- cumsum(w)
y <- theta+v
y <- ts(y)
@


<<>>=
parMLE <- function(par) dlmModPoly(1, dV = par[1], dW = par[2])
modPoly <- dlmMLE(y,parm = c(1,1),build = parMLE)
mod_filter <- dlmFilter(y, parMLE(modPoly$par))
mod_smooth <- dlmSmooth(mod_filter)
#plot(t,theta,type="l")
#lines(t,mod_filter$m[-1],col=2)
@


<<graf7,fig.cap="Ejemplo de un proceso de espacio de estado y su estimación.">>=
myguide <- guide_legend(keywidth = unit(1, "cm"))

data.frame(t,y,theta,estimacion=mod_filter$m[-1])  %>%  gather(serie,valor,-t) %>% 
  cbind(tipo=factor(c(rep(.5,N),rep(1,N),rep(1,N)))) %>%
  ggplot()+aes(x=t,y=valor,col=serie,alpha=tipo)+geom_line()+
  scale_alpha_discrete(range = c(.5,1),guide=F)+scale_color_manual(values=c("theta"='#F8766F',"y"='#7CAE00',"estimacion"="#9999CC"),guide=myguide)+theme_bw()
@

<<graf7b,fig.cap="Ejemplo de un proceso de espacio de estado y su estimación.">>=
data.frame(t,y,theta, 
           filtro = mod_filter$m[-1], suave=mod_smooth$s[-1], pred1=mod_filter$f )  %>%  
  gather(tipo, estimacion, filtro, suave, pred1) %>% 
  gather( serie, valor, -t, -tipo ) %>% 
  ggplot(aes(x=t,y=valor,col=serie)) + geom_line() + 
    facet_grid(~tipo) +
  scale_color_manual( values=c("theta"='black',"y"='grey','estimacion'='red')) +
  theme_bw()
@


% \vspace{-.75em}
% \captionof{figure}[Ejemplo de un proceso de espacio de estado]{Ejemplo de un proceso de espacio de estado y su estimación. %En \thetaline se representa el proceso \textit{no-observable}, en \yeline se representa su observación.
% }
% \label{fig:graf7}

El paquete \verb|dlm| permite trabajar con toda la familia de modelos lineales dinámicos. Si el objeto \verb|y| contiene una de las series de temperaturas, el siguiente programa nos dará la estimación del modelo.

Lo primero es estimar los parámetros desconocidos del modelo con la función \verb|dlmMLE|, que aproximará una estimación óptima, con un algoritmo iterativo. Para ello, primero debemos crear una función auxiliar (\verb|parMLE|), cuyo argumento sea un vector de valores iniciales propuesto para los parámetros: \\
\verb|parMLE <- function(par) dlmModPoly(1, dV = par[1], dW = par[2])|. En nuestro caso desconocemos $V_t$ y $W_t$, la varianza del ruido de evolución y la varianza del ruido de observación.

En este caso, si el objeto \verb|y| contiene la serie de datos, la función \verb|dlmMLE| devolverá el modelo, con los parámetros estimados:\\
\verb|mod<- modPoly <- dlmMLE(y,parm = c(1,1),build = parMLE)|

Una vez estimado el modelo, podemos aplicar el filtro de Kalman (\verb|dlmFilter|) para obtener estimaciones de la esperanza \textit{a posteriori}:\\
\verb|mod_filter <- dlmFilter(y, parMLE(modPoly$par))|


<<echo=T,eval=F>>=
parMLE <- function(par) dlmModPoly(1, dV = par[1], dW = par[2])
modPoly <- dlmMLE(y,parm = c(1,1),build = parMLE)
mod_filter <- dlmFilter(y, parMLE(modPoly$par))
mof_filter$m
@


\section{Modelo estacional para el modelado de temperaturas}\label{DLMtemp}

Modelaremos la serie de mínimas y máximas de forma independiente, utilizaremos el mismo modelo para ambas.

Dada la fuerte característica estacional de los datos de temperaturas, es apropiado modelarla como una función periódica más un ruido aleatorio. En este caso, el proceso latente será modelado como una función de período 365s y su dinámica no será aleatoria, esto se traduce en imponer matrices de varianza nulas para la ecuación de evolución.
Tal función está caracterizada por un vector $\alpha \in \RR^{365}$. La representación de $\alpha$ en la base canónica nos habla de su naturaleza temporal -\textit{qué temperatura esperamos cada día del año}-. Por distintos motivos será de mayor interés considerar la representación de $\alpha$ en una base de Fourier. Esto nos permitirá trabajar en un espacio de dimensión significativamente menor, con muy poca pérdida de información, dado que unos pocos armónicos (en nuestro caso 2) tienen coeficientes de fourier `significativos', definiendo así un criterio para descartar armónicos de mayor frecuencia, responsables de la rugosidad de la serie.

En este caso el modelo será:
$$\theta_t=\left(\begin{array}{lr}
S_1:=& a_1\cos\left(\frac{2\pi t}{365}\right) + b_1 \sin\left(\frac{2\pi t}{365}\right) \\
S_1^*:=& -a_1\sin\left(\frac{2\pi t}{365}\right) + b_1 \cos\left(\frac{2\pi t}{365}\right) \\
S_2:= &a_2\cos\left(\frac{4\pi t}{365}\right) + b_2 \sin\left(\frac{4\pi t}{365}\right) \\
S_2^*:=& -a_2\sin\left(\frac{4\pi t}{365}\right) + b_2 \cos\left(\frac{4\pi t}{365}\right) \\
\end{array}\right)\; F_t=(1,0,1,0) \; \forall \, t$$

La matriz $G_t$ (constante en $t$) será una matriz diagonal por bloques, cuyos dos bloques serán matrices de rotación de ángulos horarios $\frac{2\pi}{365}$ y $\frac{4\pi}{365}$. La matriz $W_t$ se definió nula. La varianza observacional $V_t$ será estimada por máxima verosimilitud.

\subsection{Estimación de percentiles}

Como se explicó anteriormente, para caracterizar olas de frío debemos estimar los percentiles 10 de temperaturas mínimas y máximas para cada día del año. Tenemos las series temporales de los datos de mínima y máxima, a escala diaria, desde el 1-Enero de 1950 hasta el 10-Octubre de 2014, por tanto para cada día del año (del 1-Enero al 31-Diciembre) tenemos más de sesenta observaciones de temperaturas. Esto da para cada día del año una distribución de temperaturas.  %Un acercamiento a este problema se puede ver en {\color{red}[referencia a Santiago]} donde se computa el percentil empírico para cada día del año y luego, a la serie de percentiles, se le aplica un filtro de medias móviles con una ventana de 31 días para obtener una estimación suave.

En este trabajo, para la estimación de tales percentiles, nos valdremos de la distribución de $\theta_t | \{y_1,\dots,y_t\}$. Se puede probar que, bajo el modelo descripto en la expresión (\ref{eq:modelo}), se cumple que $\theta_t | \{y_1,\dots,y_t\} \sim \mathcal{N}(m_t,C_t)$, y $y_t|\theta_t \sim \mathcal{N}(Fm_t,FC_tF^T + \text{v}_t)$. El filtro de Kalman nos devuelve las secuencias $(m_t)_{1\leq t \leq T}$ y $(C_t)_{1\leq t \leq T}$ para la serie de temperaturas mínimas y máximas. Por tanto, el estimador para el percentil 10 de mínima para el día $t$ será $\hat{p}^n_{10_t}:=Fm_t+\sqrt{FC_tF^T + \text{v}_t}\times \Phi(0.10)$, donde $\Phi(x)=\p(X\leq x)$ con $X\sim N(0,1)$. Análogamente se hace lo mismo para el percentil 10 de temperaturas máximas.

\section{Implementación en R - paquete `dlm'}

% El paquete \verb|dlm| permite trabajar con toda la familia de modelos lineales dinámicos. %La función \verb|dlmMoTrig| nos permite crear objetos \verb|dlm| de 

Si el objeto \verb|y| contiene una de las series de temperaturas, el siguiente programa nos dará la estimación del modelo.

<<echo=T,eval=F>>=
parMLE <- function(par)  dlmModTrig(s = 365,q=2, dV = par, dW = 0)
mod<- dlmMLE(y,parm = 16,build= parMLE)
Tn.filter <- dlmFilter(y,parMLE(mod$par))
@

El objeto \verb|Tn.filter$m| tendrá la estimación.
% 
% Lo primero es estimar la varianza observacional con la función \verb|dlmMLE|, que aproximará una estimación óptima, con un algoritmo iterativo. Para ello, primero debemos crear una función auxiliar (\verb|parMLE|), cuyo argumento sea un valor inicial propuesto para el parámetro, que retorne un objeto de la clase \verb|dlm|, en este caso de la familia de modelos trigonométricos, donde la frecuencia es 365. Le especificamos que mantenga 2 armónicos y descarte el resto:\\
% \verb|parMLE <- function(par)  dlmModTrig(s = 365,q=2, dV = par, dW = 0)|
% 
% La función \verb|dlmMLE| devolverá el modelo, con el/los parámetros estimados:\\
% \verb|mod<- dlmMLE(y,parm = 16,build= parMLE)|
% 
% Una vez estimado el modelo, podemos aplicar el filtro de Kalman (\verb|dlmFilter|) para obtener estimaciones de la esperanza \textit{a posteriori}:\\
% \verb|Tn.filter <- dlmFilter(y,parMLE(mod$par))|
 
El paquete \verb|dlm| permite trabajar con toda la familia de modelos lineales dinámicos. %La función \verb|dlmMoTrig| nos permite crear objetos \verb|dlm| de 

Si el objeto \verb|y| contiene una de las series de temperaturas, el siguiente programa nos dará la estimación del modelo.

Lo primero es estimar la varianza observacional con la función \verb|dlmMLE|, que aproximará una estimación óptima, con un algoritmo iterativo. Para ello, primero debemos crear una función auxiliar (\verb|parMLE|), cuyo argumento sea un valor inicial propuesto para el parámetro, que retorne un objeto de la clase \verb|dlm|, en este caso de la familia de modelos trigonométricos, donde la frecuencia es 365. Le especificamos que mantenga 2 armónicos y descarte el resto:\\
\verb|parMLE <- function(par)  dlmModTrig(s = 365,q=2, dV = par, dW = 0)|

La función \verb|dlmMLE| devolverá el modelo, con el/los parámetros estimados:\\
\verb|mod<- dlmMLE(y,parm = 16,build= parMLE)|

Una vez estimado el modelo, podemos aplicar el filtro de Kalman (\verb|dlmFilter|) para obtener estimaciones de la esperanza \textit{a posteriori}:\\
\verb|Tn.filter <- dlmFilter(y,parMLE(mod$par))|

En la figura \ref{fig:graf6} se muestra en un período de tres años, las series de mínima y máxima y la estimación de su valor esperado mediante el filtro de Kalman.

\section{Resultados}

\begin{center}
\includegraphics[width=.45\textwidth ,height=15em]{graf6.png}
\vspace{-.75em}
\captionof{figure}{Gráfico de mínimas y máximas del 1966 al 1969, y la estimación del valor esperado del proceso, mediante el filtro de Kalman}
\label{fig:graf6}
\end{center}

\begin{center}
\includegraphics[width=.4\textwidth,height=21em]{graf4.png}
\captionof{figure}{Mínimas y máximas del 1966 al 1969, percentiles 10, y olas de frío detectadas}
\label{fig:graf4}
\end{center}

\begin{scriptsize}
\begin{center}
\begin{tabular}{lrrrr}
  \hline
Fecha & Mín & Máx & p10 mín & p10 máx \\ 
  \hline
1967-06-09 & 5.40 & 3.14 & 15.50 & 11.25 \\ 
  1967-06-10 & -0.30 & 3.08 & 10.20 & 11.19 \\ 
  1967-06-11 & 1.50 & 3.03 & 7.40 & 11.12 \\ 
  1967-06-12 & -0.90 & 2.97 & 4.90 & 11.06 \\ 
  1967-06-13 & -3.70 & 2.92 & 5.30 & 11.00 \\ 
  1967-06-14 & -4.40 & 2.86 & 7.20 & 10.94 \\ 
  1967-06-15 & -3.00 & 2.81 & 8.80 & 10.88 \\ 
  1967-06-16 & 3.90 & 2.77 & 12.30 & 10.83 \\ 
   \hline
\end{tabular}
\captionof{table}{Mínimas, máximas y percentiles 10 de mínimas y máximas, en ocasión de ola de frío detectada, desde el 10 al 16 de junio de 1967, }
\end{center}
\end{scriptsize}


\textbf{Palabras clave}:  
\textbf{C\'ODIGOS JEL}: 
\vspace{0.5cm}
\textbf{Clasificaci\'on MSC2010}: 

\begin{center}
	\textbf{titulo in english...}
\end{center}

\begin{center}
authors ... 
\end{center}

\begin{center}
	\textbf{ABSTRACT}
\end{center}

oh boy .... 

\textbf{Key words}:  

\textbf{JEL CODES}: 

\textbf{Mathematics Subject Classification MSC2010}: 

\pagebreak
\pagestyle{fancy}
\fancyhf{}
\fancyhead[RE,LO]{titulo }
\fancyhead[LE,RO]{\thepage}
\fancyfoot[RE,RO]{autores abreviados .. }
\fancyfoot[LE,LO]{DT (17/3)-Instituto de Estadística}


\renewcommand{\refname}{Referencias Bibliográficas}

%% Bibliografica usando bibtex
% \pagebreak
% \bibliographystyle{apalike-es}
% \bibliography{biblio/poLCA}

\begin{itemize}
\item Petris, G., Petrone, S., \& Campagnoli, P. (2009). Dynamic linear models. In Dynamic Linear Models with R (pp. 31-84). Springer, New York, NY.

\item Niemi, J. (2012). STAT 615: Advanced Bayesian Methods [Beamer slides]. Retrieved from http://www.jarad.me/courses/stat615/slides/DLMs/DLMs.pdf

\end{itemize}

\pagebreak
\thispagestyle{empty}
\begin{center}

\vspace{1.5 cm}
{\Huge Instituto de Estadística} 
\noindent\rule{18cm}{0.4pt}

\vspace{0.5 cm}
\pagestyle{fancy}
{\Huge Documentos de Trabajo}\\
\thispagestyle{empty}
%\noindent\rule{18cm}{0.4pt\includegraphics[width=0.50\textwidth]{grafi/logo_iesta.png}}
\vspace{1.5 cm}
\includegraphics[width=0.40\textwidth]{logo_iesta.png}

%\begin{center}
\thispagestyle{empty}
\vspace{4.5 cm}

\begin{flushright}
	\textbf{\large Eduardo Acevedo 1139. CP 11200
		Montevideo, Uruguay\\
		Teléfonos y fax: (598) 2410 2564 - 2418 7381\\
		Correo: ddt@iesta.edu.uy\\
		www.iesta.edu.uy\\
		Área Publicaciones\\}	
\end{flushright}

\vspace{1.5 cm}

\large\textbf{Diciembre, 2017}\\
\large\textbf{DT (17/3)}
\end{center}

\end{document}

